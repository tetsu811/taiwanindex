#!/usr/bin/env python3
"""
æª¢æŸ¥ FinMind å…è²»ç‰ˆæ‰€æœ‰å¯ç”¨çš„è³‡æ–™é›†å’Œæ¬„ä½
"""

import finmind
import pandas as pd
from datetime import datetime, timedelta
import json

def login_finmind():
    """ç™»å…¥ FinMind"""
    try:
        token = finmind.login('tetsu@tetsu.com', 'Tetsu123456')
        print(f"âœ… ç™»å…¥æˆåŠŸ")
        return token
    except Exception as e:
        print(f"âŒ ç™»å…¥å¤±æ•—: {e}")
        return None

def check_user_info(token):
    """æª¢æŸ¥ç”¨æˆ¶è³‡è¨Š"""
    try:
        user_info = finmind.user.get_user_info(token)
        print(f"ğŸ‘¤ ç”¨æˆ¶ç­‰ç´š: {user_info.get('level_title', 'Unknown')}")
        print(f"ğŸ“Š API é™åˆ¶: {user_info.get('api_request_limit', 'Unknown')}")
        return user_info
    except Exception as e:
        print(f"âŒ ç„¡æ³•å–å¾—ç”¨æˆ¶è³‡è¨Š: {e}")
        return None

def get_available_datasets(token):
    """å–å¾—å¯ç”¨çš„è³‡æ–™é›†æ¸…å–®"""
    try:
        datasets = finmind.data.get_available_datasets(token)
        print(f"ğŸ“‹ å¯ç”¨è³‡æ–™é›†: {datasets}")
        return datasets
    except Exception as e:
        print(f"âŒ ç„¡æ³•å–å¾—è³‡æ–™é›†æ¸…å–®: {e}")
        return []

def test_dataset(token, dataset_name, start_date, end_date):
    """æ¸¬è©¦ç‰¹å®šè³‡æ–™é›†"""
    print(f"\nğŸ” æ¸¬è©¦è³‡æ–™é›†: {dataset_name}")
    print(f"ğŸ“… æ—¥æœŸç¯„åœ: {start_date} åˆ° {end_date}")
    
    try:
        # å˜—è©¦å–å¾—è³‡æ–™
        data = finmind.data.get_data(
            token, 
            dataset=dataset_name, 
            start_date=start_date, 
            end_date=end_date
        )
        
        if not data.empty:
            print(f"âœ… æˆåŠŸå–å¾—è³‡æ–™!")
            print(f"ğŸ“Š è³‡æ–™å½¢ç‹€: {data.shape}")
            print(f"ğŸ·ï¸ æ¬„ä½: {list(data.columns)}")
            print(f"ğŸ“ å‰3ç­†è³‡æ–™:")
            print(data.head(3))
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸å€¼è³‡æ–™
            numeric_columns = data.select_dtypes(include=['number']).columns.tolist()
            if numeric_columns:
                print(f"ğŸ”¢ æ•¸å€¼æ¬„ä½: {numeric_columns}")
                
                # é¡¯ç¤ºæ•¸å€¼æ¬„ä½çš„çµ±è¨ˆè³‡è¨Š
                for col in numeric_columns[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                    if col in data.columns:
                        print(f"   {col}: {data[col].describe()}")
            
            return data
        else:
            print(f"âš ï¸ è³‡æ–™ç‚ºç©º")
            return None
            
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
        return None

def test_taiwan_datasets(token):
    """æ¸¬è©¦æ‰€æœ‰å°è‚¡ç›¸é—œçš„è³‡æ–™é›†"""
    print("\n" + "="*60)
    print("ğŸ‡¹ğŸ‡¼ æ¸¬è©¦æ‰€æœ‰å°è‚¡ç›¸é—œè³‡æ–™é›†")
    print("="*60)
    
    # è¨­å®šæ¸¬è©¦æ—¥æœŸï¼ˆä½¿ç”¨æœ€è¿‘çš„æ—¥æœŸï¼‰
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    
    # æ‰€æœ‰å¯èƒ½çš„å°è‚¡è³‡æ–™é›†
    taiwan_datasets = [
        'TaiwanStockInfo',                    # å°è‚¡ç¸½è¦½
        'TaiwanStockPrice',                   # å°è‚¡åƒ¹æ ¼
        'TaiwanStockIndex',                   # å°è‚¡æŒ‡æ•¸
        'TaiwanStockInstitutionalInvestorsBuySell',  # ä¸‰å¤§æ³•äººè²·è³£è¶…
        'TaiwanStockMarginPurchase',          # èè³‡èåˆ¸
        'TaiwanStockShortSale',               # å€Ÿåˆ¸
        'TaiwanStockGovernmentBankBuySell',  # å…«å¤§è¡Œåº«è²·è³£
        'TaiwanStockTradingDailyReport',     # å°è‚¡äº¤æ˜“æ—¥å ±
        'TaiwanStockWarrantTradingDailyReport',  # æ¬Šè­‰äº¤æ˜“æ—¥å ±
        'TaiwanStockBalanceSheet',            # è³‡ç”¢è² å‚µè¡¨
        'TaiwanStockFinancialStatements',     # è²¡å‹™å ±è¡¨
        'TaiwanStockCashDividend',            # ç¾é‡‘è‚¡åˆ©
        'TaiwanStockStockDividend',           # è‚¡ç¥¨è‚¡åˆ©
        'TaiwanStockShareholding',            # è‚¡æ¬Šåˆ†æ•£
        'TaiwanStockShareholdingChange',      # è‚¡æ¬Šè®Šå‹•
        'TaiwanStockNews',                    # å°è‚¡æ–°è
        'TaiwanStockNewsCategory',            # å°è‚¡æ–°èåˆ†é¡
        'TaiwanStockNewsTag',                 # å°è‚¡æ–°èæ¨™ç±¤
        'TaiwanStockNewsContent',             # å°è‚¡æ–°èå…§å®¹
        'TaiwanStockNewsSummary',             # å°è‚¡æ–°èæ‘˜è¦
        'TaiwanStockNewsTitle',               # å°è‚¡æ–°èæ¨™é¡Œ
        'TaiwanStockNewsUrl',                 # å°è‚¡æ–°èç¶²å€
        'TaiwanStockNewsDate',                # å°è‚¡æ–°èæ—¥æœŸ
        'TaiwanStockNewsSource',              # å°è‚¡æ–°èä¾†æº
        'TaiwanStockNewsAuthor',              # å°è‚¡æ–°èä½œè€…
        'TaiwanStockNewsContentLength',       # å°è‚¡æ–°èå…§å®¹é•·åº¦
        'TaiwanStockNewsTitleLength',         # å°è‚¡æ–°èæ¨™é¡Œé•·åº¦
        'TaiwanStockNewsUrlLength',           # å°è‚¡æ–°èç¶²å€é•·åº¦
        'TaiwanStockNewsDateLength',          # å°è‚¡æ–°èæ—¥æœŸé•·åº¦
        'TaiwanStockNewsSourceLength',        # å°è‚¡æ–°èä¾†æºé•·åº¦
        'TaiwanStockNewsAuthorLength',        # å°è‚¡æ–°èä½œè€…é•·åº¦
    ]
    
    successful_datasets = []
    failed_datasets = []
    
    for dataset in taiwan_datasets:
        try:
            data = test_dataset(token, dataset, start_date, end_date)
            if data is not None and not data.empty:
                successful_datasets.append(dataset)
            else:
                failed_datasets.append(dataset)
        except Exception as e:
            print(f"âŒ {dataset} æ¸¬è©¦ç•°å¸¸: {e}")
            failed_datasets.append(dataset)
    
    # ç¸½çµçµæœ
    print(f"\n" + "="*60)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("="*60)
    print(f"âœ… æˆåŠŸçš„è³‡æ–™é›† ({len(successful_datasets)}):")
    for dataset in successful_datasets:
        print(f"   - {dataset}")
    
    print(f"\nâŒ å¤±æ•—çš„è³‡æ–™é›† ({len(failed_datasets)}):")
    for dataset in failed_datasets:
        print(f"   - {dataset}")
    
    return successful_datasets, failed_datasets

def test_global_datasets(token):
    """æ¸¬è©¦å…¨çƒå¸‚å ´è³‡æ–™é›†"""
    print("\n" + "="*60)
    print("ğŸŒ æ¸¬è©¦å…¨çƒå¸‚å ´è³‡æ–™é›†")
    print("="*60)
    
    end_date = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    
    global_datasets = [
        'USStockInfo',                        # ç¾è‚¡ç¸½è¦½
        'USStockPrice',                       # ç¾è‚¡åƒ¹æ ¼
        'USStockIndex',                       # ç¾è‚¡æŒ‡æ•¸
        'USStockInstitutionalInvestorsBuySell',  # ç¾è‚¡æ³•äººè²·è³£è¶…
        'USStockMarginPurchase',              # ç¾è‚¡èè³‡èåˆ¸
        'USStockShortSale',                   # ç¾è‚¡å€Ÿåˆ¸
        'USStockTradingDailyReport',         # ç¾è‚¡äº¤æ˜“æ—¥å ±
        'USStockBalanceSheet',                # ç¾è‚¡è³‡ç”¢è² å‚µè¡¨
        'USStockFinancialStatements',         # ç¾è‚¡è²¡å‹™å ±è¡¨
        'USStockCashDividend',                # ç¾è‚¡ç¾é‡‘è‚¡åˆ©
        'USStockStockDividend',               # ç¾è‚¡è‚¡ç¥¨è‚¡åˆ©
        'USStockShareholding',                # ç¾è‚¡è‚¡æ¬Šåˆ†æ•£
        'USStockShareholdingChange',          # ç¾è‚¡è‚¡æ¬Šè®Šå‹•
        'USStockNews',                        # ç¾è‚¡æ–°è
        'USStockNewsCategory',                # ç¾è‚¡æ–°èåˆ†é¡
        'USStockNewsTag',                     # ç¾è‚¡æ–°èæ¨™ç±¤
        'USStockNewsContent',                 # ç¾è‚¡æ–°èå…§å®¹
        'USStockNewsSummary',                 # ç¾è‚¡æ–°èæ‘˜è¦
        'USStockNewsTitle',                   # ç¾è‚¡æ–°èæ¨™é¡Œ
        'USStockNewsUrl',                     # ç¾è‚¡æ–°èç¶²å€
        'USStockNewsDate',                    # ç¾è‚¡æ–°èæ—¥æœŸ
        'USStockNewsSource',                  # ç¾è‚¡æ–°èä¾†æº
        'USStockNewsAuthor',                  # ç¾è‚¡æ–°èä½œè€…
        'USStockNewsContentLength',           # ç¾è‚¡æ–°èå…§å®¹é•·åº¦
        'USStockNewsTitleLength',             # ç¾è‚¡æ–°èæ¨™é¡Œé•·åº¦
        'USStockNewsUrlLength',               # ç¾è‚¡æ–°èç¶²å€é•·åº¦
        'USStockNewsDateLength',              # ç¾è‚¡æ–°èæ—¥æœŸé•·åº¦
        'USStockNewsSourceLength',            # ç¾è‚¡æ–°èä¾†æºé•·åº¦
        'USStockNewsAuthorLength',            # ç¾è‚¡æ–°èä½œè€…é•·åº¦
    ]
    
    successful_datasets = []
    failed_datasets = []
    
    for dataset in global_datasets:
        try:
            data = test_dataset(token, dataset, start_date, end_date)
            if data is not None and not data.empty:
                successful_datasets.append(dataset)
            else:
                failed_datasets.append(dataset)
        except Exception as e:
            print(f"âŒ {dataset} æ¸¬è©¦ç•°å¸¸: {e}")
            failed_datasets.append(dataset)
    
    # ç¸½çµçµæœ
    print(f"\n" + "="*60)
    print("ğŸ“Š å…¨çƒå¸‚å ´æ¸¬è©¦çµæœç¸½çµ")
    print("="*60)
    print(f"âœ… æˆåŠŸçš„è³‡æ–™é›† ({len(successful_datasets)}):")
    for dataset in successful_datasets:
        print(f"   - {dataset}")
    
    print(f"\nâŒ å¤±æ•—çš„è³‡æ–™é›† ({len(failed_datasets)}):")
    for dataset in failed_datasets:
        print(f"   - {dataset}")
    
    return successful_datasets, failed_datasets

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æª¢æŸ¥ FinMind å…è²»ç‰ˆæ‰€æœ‰å¯ç”¨è³‡æ–™é›†")
    
    # ç™»å…¥
    token = login_finmind()
    if not token:
        return
    
    # æª¢æŸ¥ç”¨æˆ¶è³‡è¨Š
    user_info = check_user_info(token)
    
    # å–å¾—å¯ç”¨è³‡æ–™é›†æ¸…å–®
    available_datasets = get_available_datasets(token)
    
    # æ¸¬è©¦å°è‚¡è³‡æ–™é›†
    taiwan_success, taiwan_failed = test_taiwan_datasets(token)
    
    # æ¸¬è©¦å…¨çƒå¸‚å ´è³‡æ–™é›†
    global_success, global_failed = test_global_datasets(token)
    
    # æœ€çµ‚ç¸½çµ
    print(f"\n" + "="*60)
    print("ğŸ¯ æœ€çµ‚ç¸½çµ")
    print("="*60)
    print(f"ğŸ“Š ç¸½å…±æ¸¬è©¦çš„è³‡æ–™é›†: {len(taiwan_success) + len(taiwan_failed) + len(global_success) + len(global_failed)}")
    print(f"âœ… æˆåŠŸçš„è³‡æ–™é›†: {len(taiwan_success) + len(global_success)}")
    print(f"âŒ å¤±æ•—çš„è³‡æ–™é›†: {len(taiwan_failed) + len(global_failed)}")
    print(f"ğŸ‡¹ğŸ‡¼ å°è‚¡æˆåŠŸ: {len(taiwan_success)}")
    print(f"ğŸŒ å…¨çƒæˆåŠŸ: {len(global_success)}")
    
    # ä¿å­˜çµæœåˆ°æª”æ¡ˆ
    results = {
        'user_info': user_info,
        'available_datasets': available_datasets,
        'taiwan_successful': taiwan_success,
        'taiwan_failed': taiwan_failed,
        'global_successful': global_success,
        'global_failed': global_failed,
        'timestamp': datetime.now().isoformat()
    }
    
    with open('finmind_dataset_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜åˆ° finmind_dataset_results.json")

if __name__ == "__main__":
    main()
