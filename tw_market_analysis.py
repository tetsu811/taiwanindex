"""
Taiwan stock market trend analysis script.

This script fetches Taiwan stock market data from FinMind API and sends daily reports via LINE.
First logs in to FinMind to get a fresh token.
"""

from __future__ import annotations

import sys
import os
from datetime import datetime, time, timedelta
from typing import Optional, Tuple

import pandas as pd
import requests


def is_after_5pm_taipei(now: datetime | None = None) -> bool:
    """Return True if current local time in Asia/Taipei is after 17:00."""
    try:
        from zoneinfo import ZoneInfo
        tz = ZoneInfo("Asia/Taipei")
        now_tpe = (now or datetime.now(tz)).astimezone(tz)
    except Exception:
        now_tpe = now or datetime.now()

    five_pm = time(17, 0, 0)
    return now_tpe.time() >= five_pm


def get_two_latest_trading_dates_twse() -> Tuple[str, str]:
    """å–å¾—æœ€è¿‘å…©å€‹äº¤æ˜“æ—¥"""
    end = datetime.now().date()
    candidates = [end - timedelta(days=i) for i in range(0, 14)]
    valid: list[str] = []
    
    for d in candidates:
        try:
            # ä½¿ç”¨ TWSE API æª¢æŸ¥æ˜¯å¦ç‚ºäº¤æ˜“æ—¥
            d_str = d.strftime("%Y%m%d")
            resp = requests.get(
                "https://www.twse.com.tw/exchangeReport/MI_INDEX",
                params={"response": "json", "date": d_str, "type": "ALL"},
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=20
            )
            if resp.status_code == 200:
                data = resp.json()
                if data.get("stat") == "OK":
                    valid.append(d.isoformat())
                    if len(valid) >= 2:
                        break
        except Exception:
            continue
    
    if len(valid) >= 2:
        return valid[0], valid[1]
    
    # å¾Œå‚™æ–¹æ¡ˆ
    return end.isoformat(), (end - timedelta(days=1)).isoformat()


def login_finmind() -> str:
    """ç™»å…¥ FinMind å–å¾—æ–°çš„ token"""
    login_url = "https://api.finmindtrade.com/api/v4/login"
    
    # æ ¹æ“šæ–‡æª”ï¼Œä½¿ç”¨ user_id å’Œ password
    login_data = {
        "user_id": "tetsu",
        "password": "Tt810811"
    }
    
    try:
        print(f"[Info] å˜—è©¦ç™»å…¥ FinMindï¼Œä½¿ç”¨åƒæ•¸ï¼š{list(login_data.keys())}")
        print(f"[Debug] ç™»å…¥è³‡æ–™ï¼š{login_data}")
        
        # ä½¿ç”¨ data è€Œä¸æ˜¯ jsonï¼Œå› ç‚ºæ–‡æª”ç¯„ä¾‹ä½¿ç”¨ data
        login_resp = requests.post(login_url, data=login_data, timeout=20)
        print(f"[Debug] ç™»å…¥å›æ‡‰ï¼š{login_resp.status_code} {login_resp.text[:200]}")
        
        if login_resp.status_code == 200:
            resp_data = login_resp.json()
            if resp_data.get("msg") == "success" and resp_data.get("status") == 200:
                new_token = resp_data.get("token")
                if new_token:
                    print(f"[Info] ç™»å…¥æˆåŠŸï¼Œå–å¾—æ–° token")
                    return new_token
                else:
                    print(f"[Warn] ç™»å…¥æˆåŠŸä½†æœªå–å¾— token")
            else:
                print(f"[Warn] ç™»å…¥å›æ‡‰æ ¼å¼ç•°å¸¸ï¼š{resp_data}")
        else:
            print(f"[Warn] ç™»å…¥å¤±æ•—ï¼š{login_resp.status_code} {login_resp.text}")
                    
    except Exception as exc:
        print(f"[Warn] ç™»å…¥ç•°å¸¸ï¼š{exc}")
    
    # å¦‚æœç™»å…¥å¤±æ•—ï¼Œä½¿ç”¨èˆŠ token
    print("[Warn] ç™»å…¥å¤±æ•—ï¼Œä½¿ç”¨èˆŠ token")
    OLD_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0wOC0yOCAxNzowMDowMSIsInVzZXJfaWQiOiJ0ZXRzdSIsImlwIjoiMTI0LjIxOC4yMTYuMTgzIiwiZXhwIjoxNzU2OTc2NDAxfQ.AjeOEd4TUeRC_j8D_uoGiD2uiHtNuYoLEMzyA0M_zoQ"
    return OLD_TOKEN


def check_user_info(token: str) -> None:
    """æª¢æŸ¥ç”¨æˆ¶è³‡è¨Šå’Œæ¬Šé™"""
    try:
        user_info_url = "https://api.web.finmindtrade.com/v2/user_info"
        headers = {"Authorization": f"Bearer {token}"}
        user_resp = requests.get(user_info_url, headers=headers, timeout=20)
        print(f"[Debug] ç”¨æˆ¶è³‡è¨Šæª¢æŸ¥ï¼š{user_resp.status_code} {user_resp.text[:500]}")
        
        if user_resp.status_code == 200:
            user_data = user_resp.json()
            print(f"[Info] ç”¨æˆ¶è³‡è¨Šï¼š{user_data}")
        else:
            print(f"[Warn] ç”¨æˆ¶è³‡è¨Šæª¢æŸ¥å¤±æ•—ï¼š{user_resp.status_code}")
            
    except Exception as exc:
        print(f"[Warn] ç”¨æˆ¶è³‡è¨Šæª¢æŸ¥ç•°å¸¸ï¼š{exc}")


def get_available_datasets(token: str) -> None:
    """æŸ¥è©¢å¯ç”¨çš„è³‡æ–™é›†æ¸…å–®"""
    try:
        # ä½¿ç”¨ datalist API æŸ¥è©¢å¯ç”¨è³‡æ–™é›†
        datalist_url = "https://api.finmindtrade.com/api/v4/datalist"
        headers = {"Authorization": f"Bearer {token}"}
        
        print(f"[Info] æŸ¥è©¢å¯ç”¨è³‡æ–™é›†æ¸…å–®...")
        resp = requests.get(datalist_url, headers=headers, timeout=20)
        
        if resp.status_code == 200:
            data = resp.json()
            print(f"[Info] è³‡æ–™é›†æ¸…å–®æŸ¥è©¢æˆåŠŸ")
            print(f"[Debug] å›æ‡‰å…§å®¹ï¼š{data}")
            
            if data.get("data"):
                datasets = data["data"]
                print(f"[Info] æ‰¾åˆ° {len(datasets)} å€‹å¯ç”¨è³‡æ–™é›†ï¼š")
                for i, dataset in enumerate(datasets[:20]):  # åªé¡¯ç¤ºå‰20å€‹
                    print(f"  {i+1}. {dataset}")
                if len(datasets) > 20:
                    print(f"  ... é‚„æœ‰ {len(datasets) - 20} å€‹è³‡æ–™é›†")
            else:
                print(f"[Warn] æœªæ‰¾åˆ°è³‡æ–™é›†æ¸…å–®")
        else:
            print(f"[Warn] è³‡æ–™é›†æ¸…å–®æŸ¥è©¢å¤±æ•—ï¼š{resp.status_code} {resp.text[:200]}")
            
    except Exception as exc:
        print(f"[Warn] è³‡æ–™é›†æ¸…å–®æŸ¥è©¢ç•°å¸¸ï¼š{exc}")


def get_dataset_fields(token: str, dataset: str) -> None:
    """æŸ¥è©¢ç‰¹å®šè³‡æ–™é›†çš„æ¬„ä½åç¨±å°ç…§"""
    try:
        # ä½¿ç”¨ translation API æŸ¥è©¢æ¬„ä½åç¨±å°ç…§
        translation_url = "https://api.finmindtrade.com/api/v4/translation"
        headers = {"Authorization": f"Bearer {token}"}
        params = {"dataset": dataset}
        
        print(f"[Info] æŸ¥è©¢ {dataset} çš„æ¬„ä½åç¨±å°ç…§...")
        resp = requests.get(translation_url, headers=headers, params=params, timeout=20)
        
        if resp.status_code == 200:
            data = resp.json()
            print(f"[Info] {dataset} æ¬„ä½åç¨±å°ç…§æŸ¥è©¢æˆåŠŸ")
            print(f"[Debug] å›æ‡‰å…§å®¹ï¼š{data}")
            
            if data.get("data"):
                fields = data["data"]
                print(f"[Info] {dataset} æœ‰ {len(fields)} å€‹æ¬„ä½ï¼š")
                for field in fields:
                    print(f"  - {field}")
            else:
                print(f"[Warn] {dataset} æœªæ‰¾åˆ°æ¬„ä½è³‡è¨Š")
        else:
            print(f"[Warn] {dataset} æ¬„ä½åç¨±å°ç…§æŸ¥è©¢å¤±æ•—ï¼š{resp.status_code} {resp.text[:200]}")
            
    except Exception as exc:
        print(f"[Warn] {dataset} æ¬„ä½åç¨±å°ç…§æŸ¥è©¢ç•°å¸¸ï¼š{exc}")


def fetch_dataset(dataset: str, date: str, data_id: Optional[str] = None, prev_date: Optional[str] = None) -> pd.DataFrame:
    """å¾ FinMind API å–å¾—è³‡æ–™"""
    # å…ˆç™»å…¥å–å¾—æ–° token
    api_token = login_finmind()
    
    # å˜—è©¦ v2 API ç«¯é»
    base_urls = [
        "https://api.web.finmindtrade.com/v2/data",  # v2 API
        "https://api.finmindtrade.com/api/v4/data"   # v4 API (å‚™ç”¨)
    ]
    
    headers = {"Authorization": f"Bearer {api_token}"}
    
    for base_url in base_urls:
        try:
            print(f"[Debug] å˜—è©¦ {base_url} å–å¾— {dataset}")
            
            # å„ªå…ˆä½¿ç”¨æ—¥æœŸç¯„åœæŸ¥è©¢
            if prev_date:
                params = {
                    "dataset": dataset,
                    "start_date": prev_date,
                    "end_date": date,
                }
                if data_id is not None:
                    params["data_id"] = data_id
                
                resp = requests.get(base_url, params=params, headers=headers, timeout=20)
                if resp.ok:
                    data = resp.json().get("data", [])
                    df = pd.DataFrame(data)
                    print(f"[Info] æˆåŠŸä½¿ç”¨ {base_url} å–å¾— {dataset} (æ—¥æœŸç¯„åœ)")
                    return df.reset_index(drop=True)
            
            # å–®æ—¥æŸ¥è©¢
            params = {"dataset": dataset, "date": date}
            if data_id is not None:
                params["data_id"] = data_id
            
            resp = requests.get(base_url, params=params, headers=headers, timeout=20)
            
            if resp.status_code == 200:
                data = resp.json().get("data", [])
                df = pd.DataFrame(data)
                print(f"[Info] æˆåŠŸä½¿ç”¨ {base_url} å–å¾— {dataset} (å–®æ—¥)")
                return df.reset_index(drop=True)
            else:
                print(f"[Warn] {base_url} å–å¾— {dataset} æ–¼ {date} å¤±æ•—ï¼š{resp.status_code} {resp.reason}")
                if resp.status_code == 422:
                    print(f"[Debug] 422 from {dataset}({date}): {resp.text[:200]}")
                elif resp.status_code == 400:
                    print(f"[Debug] 400 from {dataset}({date}): {resp.text[:200]}")
                    
        except Exception as exc:
            print(f"[Error] {base_url} å–å¾— {dataset} æ™‚ç™¼ç”Ÿç•°å¸¸ï¼š{exc}")
    
    print(f"[Warn] æ‰€æœ‰ API ç«¯é»éƒ½å¤±æ•—ï¼Œç„¡æ³•å–å¾— {dataset}")
    return pd.DataFrame()


def extract_single_value(df: pd.DataFrame, field: str) -> Optional[float]:
    """å¾ DataFrame ä¸­æå–å–®ä¸€æ•¸å€¼"""
    if df is None or df.empty:
        return None
    
    try:
        if field in df.columns:
            value = df[field].iloc[-1]
            if pd.notna(value):
                return float(value)
        
        # å˜—è©¦å…¶ä»–å¯èƒ½çš„æ¬„ä½åç¨±
        field_mapping = {
            'close': ['close', 'Close', 'price', 'Price', 'index', 'Index'],
            'net_buy_sell': ['net_buy_sell', 'buy_sell', 'net_value', 'value'],
            'margin_maintenance_ratio': ['margin_maintenance_ratio', 'maintain_rate', 'margin_ratio'],
            'short_sale_balance': ['short_sale_balance', 'balance', 'short_balance'],
            'foreign_investor_net_position': ['foreign_investor_net_position', 'foreign_net', 'foreign_position'],
            'advance_count': ['advance_count', 'up', 'rise', 'advancers'],
            'decline_count': ['decline_count', 'down', 'fall', 'decliners']
        }
        
        if field in field_mapping:
            for alt_field in field_mapping[field]:
                if alt_field in df.columns:
                    value = df[alt_field].iloc[-1]
                    if pd.notna(value):
                        return float(value)
        
        return None
        
    except Exception:
        return None


def fmt(v: Optional[float]) -> str:
    """æ ¼å¼åŒ–æ•¸å€¼é¡¯ç¤º"""
    if v is None:
        return "ç„¡è³‡æ–™"
    if abs(v) >= 1000:
        return f"{v:,.0f}"
    return f"{v:,.2f}"


def send_line_push(message: str) -> None:
    """ç™¼é€ LINE é€šçŸ¥"""
    channel_access_token = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
    line_to_csv = os.getenv("LINE_TO")
    
    if not channel_access_token or not line_to_csv:
        print("[Warn] æœªè¨­å®š LINE ç’°å¢ƒè®Šæ•¸")
        return
    
    recipients = [x.strip() for x in line_to_csv.split(",") if x.strip()]
    print(f"[Info] LINE æ”¶ä»¶è€…ï¼š{recipients}")
    
    url = "https://api.line.me/v2/bot/message/push"
    headers = {
        "Authorization": f"Bearer {channel_access_token}",
        "Content-Type": "application/json",
    }
    
    try:
        for recipient in recipients:
            payload = {
                "to": recipient,
                "messages": [{"type": "text", "text": message}],
            }
            resp = requests.post(url, headers=headers, json=payload, timeout=20)
            if resp.status_code == 200:
                print(f"[Info] LINE æ¨é€æˆåŠŸï¼š{recipient}")
            else:
                print(f"[Warn] LINE æ¨é€å¤±æ•—ï¼š{resp.status_code} {resp.text}")
    except Exception as exc:
        print(f"[Warn] LINE æ¨é€ç•°å¸¸ï¼š{exc}")


def check_all_taiwan_datasets(token):
    """æª¢æŸ¥æ‰€æœ‰å°è‚¡ç›¸é—œçš„è³‡æ–™é›†"""
    print(f"\n" + "="*80)
    print("ğŸ” å…¨é¢æª¢æŸ¥æ‰€æœ‰å°è‚¡ç›¸é—œè³‡æ–™é›†")
    print("="*80)
    
    # æ‰€æœ‰å¯èƒ½çš„å°è‚¡è³‡æ–™é›†
    all_taiwan_datasets = [
        'TaiwanStockInfo',                    # å°è‚¡ç¸½è¦½
        'TaiwanStockPrice',                   # å°è‚¡åƒ¹æ ¼
        'TaiwanStockIndex',                   # å°è‚¡æŒ‡æ•¸
        'TaiwanStockInstitutionalInvestorsBuySell',  # ä¸‰å¤§æ³•äººè²·è³£è¶…
        'TaiwanStockMarginPurchase',          # èè³‡èåˆ¸
        'TaiwanStockShortSale',               # å€Ÿåˆ¸
        'TaiwanStockGovernmentBankBuySell',  # å…«å¤§è¡Œåº«è²·è³£
        'TaiwanStockTradingDailyReport',     # å°è‚¡äº¤æ˜“æ—¥å ±
        'TaiwanStockWarrantTradingDailyReport',  # æ¬Šè­‰äº¤æ˜“æ—¥å ±
        'TaiwanStockBalanceSheet',            # è³‡ç”¢è² å‚µè¡¨
        'TaiwanStockFinancialStatements',     # è²¡å‹™å ±è¡¨
        'TaiwanStockCashDividend',            # ç¾é‡‘è‚¡åˆ©
        'TaiwanStockStockDividend',           # è‚¡ç¥¨è‚¡åˆ©
        'TaiwanStockShareholding',            # è‚¡æ¬Šåˆ†æ•£
        'TaiwanStockShareholdingChange',      # è‚¡æ¬Šè®Šå‹•
        'TaiwanStockNews',                    # å°è‚¡æ–°è
        'TaiwanStockNewsCategory',            # å°è‚¡æ–°èåˆ†é¡
        'TaiwanStockNewsTag',                 # å°è‚¡æ–°èæ¨™ç±¤
        'TaiwanStockNewsContent',             # å°è‚¡æ–°èå…§å®¹
        'TaiwanStockNewsSummary',             # å°è‚¡æ–°èæ‘˜è¦
        'TaiwanStockNewsTitle',               # å°è‚¡æ–°èæ¨™é¡Œ
        'TaiwanStockNewsUrl',                 # å°è‚¡æ–°èç¶²å€
        'TaiwanStockNewsDate',                # å°è‚¡æ–°èæ—¥æœŸ
        'TaiwanStockNewsSource',              # å°è‚¡æ–°èä¾†æº
        'TaiwanStockNewsAuthor',              # å°è‚¡æ–°èä½œè€…
        'TaiwanStockNewsContentLength',       # å°è‚¡æ–°èå…§å®¹é•·åº¦
        'TaiwanStockNewsTitleLength',         # å°è‚¡æ–°èæ¨™é¡Œé•·åº¦
        'TaiwanStockNewsUrlLength',           # å°è‚¡æ–°èç¶²å€é•·åº¦
        'TaiwanStockNewsDateLength',          # å°è‚¡æ–°èæ—¥æœŸé•·åº¦
        'TaiwanStockNewsSourceLength',        # å°è‚¡æ–°èä¾†æºé•·åº¦
        'TaiwanStockNewsAuthorLength',        # å°è‚¡æ–°èä½œè€…é•·åº¦
        'TaiwanStockETF',                     # å°è‚¡ETF
        'TaiwanStockETFInfo',                 # å°è‚¡ETFè³‡è¨Š
        'TaiwanStockETFPremiumDiscount',      # å°è‚¡ETFæŠ˜æº¢åƒ¹
        'TaiwanStockETFNetValue',             # å°è‚¡ETFæ·¨å€¼
        'TaiwanStockETFTradingVolume',        # å°è‚¡ETFæˆäº¤é‡
        'TaiwanStockETFTradingValue',         # å°è‚¡ETFæˆäº¤å€¼
        'TaiwanStockETFTradingTurnover',      # å°è‚¡ETFæˆäº¤ç­†æ•¸
        'TaiwanStockETFTradingMoney',         # å°è‚¡ETFæˆäº¤é‡‘é¡
        'TaiwanStockETFTradingSpread',        # å°è‚¡ETFæˆäº¤åƒ¹å·®
        'TaiwanStockETFTradingOpen',          # å°è‚¡ETFé–‹ç›¤åƒ¹
        'TaiwanStockETFTradingHigh',          # å°è‚¡ETFæœ€é«˜åƒ¹
        'TaiwanStockETFTradingLow',           # å°è‚¡ETFæœ€ä½åƒ¹
        'TaiwanStockETFTradingClose',         # å°è‚¡ETFæ”¶ç›¤åƒ¹
        'TaiwanStockETFTradingMax',           # å°è‚¡ETFæœ€é«˜åƒ¹
        'TaiwanStockETFTradingMin',           # å°è‚¡ETFæœ€ä½åƒ¹
        'TaiwanStockETFTradingSpread',        # å°è‚¡ETFåƒ¹å·®
        'TaiwanStockETFTradingTurnover',      # å°è‚¡ETFæˆäº¤ç­†æ•¸
        'TaiwanStockETFTradingMoney',         # å°è‚¡ETFæˆäº¤é‡‘é¡
        'TaiwanStockETFTradingVolume',        # å°è‚¡ETFæˆäº¤é‡
        'TaiwanStockETFTradingValue',         # å°è‚¡ETFæˆäº¤å€¼
        'TaiwanStockETFPremiumDiscount',      # å°è‚¡ETFæŠ˜æº¢åƒ¹
        'TaiwanStockETFNetValue',             # å°è‚¡ETFæ·¨å€¼
        'TaiwanStockETFInfo',                 # å°è‚¡ETFè³‡è¨Š
        'TaiwanStockETF',                     # å°è‚¡ETF
    ]
    
    successful_datasets = []
    failed_datasets = []
    
    # ä½¿ç”¨æœ€è¿‘çš„æ—¥æœŸé€²è¡Œæ¸¬è©¦
    from datetime import datetime, timedelta
    test_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    print(f"ğŸ“… æ¸¬è©¦æ—¥æœŸ: {test_date}")
    print(f"ğŸ”¢ ç¸½å…±è¦æ¸¬è©¦ {len(all_taiwan_datasets)} å€‹è³‡æ–™é›†")
    
    for i, dataset in enumerate(all_taiwan_datasets, 1):
        print(f"\n[{i:2d}/{len(all_taiwan_datasets)}] ğŸ” æ¸¬è©¦: {dataset}")
        
        try:
            data = fetch_dataset(dataset, test_date)
            
            if data is not None and not data.empty:
                print(f"   âœ… æˆåŠŸ! è³‡æ–™å½¢ç‹€: {data.shape}")
                print(f"   ğŸ·ï¸ æ¬„ä½: {list(data.columns)}")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸å€¼è³‡æ–™
                numeric_columns = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]
                if numeric_columns:
                    print(f"   ğŸ”¢ æ•¸å€¼æ¬„ä½: {numeric_columns[:5]}...")  # åªé¡¯ç¤ºå‰5å€‹
                
                successful_datasets.append({
                    'dataset': dataset,
                    'shape': data.shape,
                    'columns': list(data.columns),
                    'numeric_columns': numeric_columns
                })
            else:
                print(f"   âš ï¸ è³‡æ–™ç‚ºç©º")
                failed_datasets.append(dataset)
                
        except Exception as e:
            print(f"   âŒ å¤±æ•—: {str(e)[:100]}...")  # åªé¡¯ç¤ºå‰100å€‹å­—å…ƒ
            failed_datasets.append(dataset)
    
    # ç¸½çµçµæœ
    print(f"\n" + "="*80)
    print("ğŸ“Š å…¨é¢æª¢æŸ¥çµæœç¸½çµ")
    print("="*80)
    print(f"âœ… æˆåŠŸçš„è³‡æ–™é›† ({len(successful_datasets)}):")
    for item in successful_datasets:
        print(f"   - {item['dataset']} ({item['shape'][0]} ç­†, {item['shape'][1]} æ¬„)")
    
    print(f"\nâŒ å¤±æ•—çš„è³‡æ–™é›† ({len(failed_datasets)}):")
    for dataset in failed_datasets:
        print(f"   - {dataset}")
    
    # åˆ†ææˆåŠŸçš„è³‡æ–™é›†
    print(f"\nğŸ” æˆåŠŸè³‡æ–™é›†åˆ†æ:")
    for item in successful_datasets:
        dataset = item['dataset']
        columns = item['columns']
        
        print(f"\nğŸ“‹ {dataset}:")
        print(f"   è³‡æ–™å½¢ç‹€: {item['shape']}")
        print(f"   æ‰€æœ‰æ¬„ä½: {columns}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åƒ¹æ ¼ç›¸é—œæ¬„ä½
        price_related = [col for col in columns if any(word in col.lower() for word in ['price', 'close', 'open', 'high', 'low', 'volume', 'amount'])]
        if price_related:
            print(f"   ğŸ’° åƒ¹æ ¼ç›¸é—œæ¬„ä½: {price_related}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ³•äººç›¸é—œæ¬„ä½
        institutional_related = [col for col in columns if any(word in col.lower() for word in ['foreign', 'investment', 'dealer', 'buy', 'sell'])]
        if institutional_related:
            print(f"   ğŸ¦ æ³•äººç›¸é—œæ¬„ä½: {institutional_related}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è²¡å‹™ç›¸é—œæ¬„ä½
        financial_related = [col for col in columns if any(word in col.lower() for word in ['revenue', 'profit', 'asset', 'liability', 'equity', 'eps', 'pe'])]
        if financial_related:
            print(f"   ğŸ“ˆ è²¡å‹™ç›¸é—œæ¬„ä½: {financial_related}")
    
    return successful_datasets, failed_datasets

def run_analysis() -> None:
    """åŸ·è¡Œå°è‚¡å¤§ç›¤åˆ†æ"""
    print("é–‹å§‹åŸ·è¡Œå°è‚¡å¤§ç›¤åˆ†æ...")
    
    # å…ˆç™»å…¥ä¸¦æª¢æŸ¥ç”¨æˆ¶è³‡è¨Š
    token = login_finmind()
    print(f"[Info] ä½¿ç”¨ token æª¢æŸ¥ç”¨æˆ¶è³‡è¨Š...")
    # æª¢æŸ¥ç”¨æˆ¶è³‡è¨Š
    user_info = check_user_info(token)
    
    # æª¢æŸ¥ç”¨æˆ¶ç­‰ç´š
    level = "Unknown"
    level_num = 0
    if user_info:
        level = user_info.get('level_title', 'Unknown')
        level_num = user_info.get('level', 0)
        print(f"ğŸ” ç”¨æˆ¶ç­‰ç´šæª¢æŸ¥:")
        print(f"   - ç­‰ç´šåç¨±: {level}")
        print(f"   - ç­‰ç´šæ•¸å­—: {level_num}")
        print(f"   - å®Œæ•´ç”¨æˆ¶è³‡è¨Š: {user_info}")
        
        if level_num < 3:
            print(f"âš ï¸ è­¦å‘Šï¼šç”¨æˆ¶ç­‰ç´š {level} (æ•¸å­—: {level_num}) å¯èƒ½ä¸æ˜¯æœ€é«˜ç­‰ç´š")
            print(f"   å»ºè­°å‡ç´šåˆ° Sponsor æˆ–æ›´é«˜ç­‰ç´š")
        else:
            print(f"âœ… ç”¨æˆ¶ç­‰ç´š {level} æ‡‰è©²æ˜¯æœ€é«˜ç­‰ç´š")
    
    # æ¸¬è©¦æ‚¨éœ€è¦çš„æ‰€æœ‰è³‡æ–™é›†
    print(f"\n[Info] é–‹å§‹æ¸¬è©¦æ‚¨éœ€è¦çš„æ‰€æœ‰è³‡æ–™é›†...")
    successful_datasets, failed_datasets = check_all_taiwan_datasets(token)
    
    # æŸ¥è©¢å¯ç”¨çš„è³‡æ–™é›†æ¸…å–®
    print(f"[Info] æŸ¥è©¢å¯ç”¨çš„è³‡æ–™é›†æ¸…å–®...")
    get_available_datasets(token)
    
    # æŸ¥è©¢ä¸€äº›å¯èƒ½æœ‰ç”¨çš„è³‡æ–™é›†çš„æ¬„ä½è³‡è¨Š
    print(f"[Info] æŸ¥è©¢å¯èƒ½æœ‰ç”¨çš„è³‡æ–™é›†æ¬„ä½è³‡è¨Š...")
    potential_datasets = [
        'TaiwanStockBalanceSheet',           # è³‡ç”¢è² å‚µè¡¨
        'TaiwanStockFinancialStatements',    # è²¡å‹™å ±è¡¨
        'TaiwanStockInstitutionalInvestorsBuySell',  # ä¸‰å¤§æ³•äººè²·è³£è¶…
        'TaiwanStockInfo'                    # å°è‚¡ç¸½è¦½ï¼ˆå·²çŸ¥å¯ç”¨ï¼‰
    ]
    for dataset in potential_datasets:
        get_dataset_fields(token, dataset)
    
    # å–å¾—æœ€è¿‘å…©å€‹äº¤æ˜“æ—¥
    today, prev = get_two_latest_trading_dates_twse()
    if not today or not prev:
        print("ç„¡æ³•å–å¾—äº¤æ˜“æ—¥è³‡è¨Š")
        return
    
    print(f"åˆ†ææ—¥æœŸï¼š{today} (å°æ¯” {prev})")
    
    # æ¸¬è©¦åŸºæœ¬è³‡æ–™é›†
    print(f"[Debug] æ¸¬è©¦åŸºæœ¬è³‡æ–™é›†...")
    test_data = fetch_dataset('TaiwanStockInfo', today)
    print(f"[Debug] TaiwanStockInfo å›æ‡‰ï¼š{len(test_data)} ç­†è³‡æ–™")
    if not test_data.empty:
        print(f"[Debug] æ¬„ä½ï¼š{list(test_data.columns)}")
        print(f"[Debug] å‰å¹¾ç­†è³‡æ–™ï¼š{test_data.head(2).to_dict()}")
        
        # åˆ†æè³‡æ–™çµæ§‹ï¼Œå°‹æ‰¾æœ‰ç”¨çš„è³‡è¨Š
        print(f"[Debug] è³‡æ–™é¡å‹åˆ†æï¼š")
        print(f"[Debug] ä¸Šå¸‚/æ«ƒè²·åˆ†å¸ƒï¼š{test_data['type'].value_counts().to_dict()}")
        print(f"[Debug] ç”¢æ¥­é¡åˆ¥æ•¸é‡ï¼š{len(test_data['industry_category'].unique())}")
        print(f"[Debug] å‰10å€‹ç”¢æ¥­é¡åˆ¥ï¼š{list(test_data['industry_category'].unique())[:10]}")
        
        # å˜—è©¦å°‹æ‰¾æ˜¯å¦æœ‰åƒ¹æ ¼ç›¸é—œçš„æ¬„ä½
        if 'close' in test_data.columns:
            print(f"[Debug] æ‰¾åˆ°æ”¶ç›¤åƒ¹æ¬„ä½ï¼Œè³‡æ–™ç¯„åœï¼š{test_data['close'].min()} - {test_data['close'].max()}")
        else:
            print(f"[Debug] æœªæ‰¾åˆ°æ”¶ç›¤åƒ¹æ¬„ä½ï¼Œå˜—è©¦å…¶ä»–å¯èƒ½çš„åƒ¹æ ¼æ¬„ä½...")
            price_columns = [col for col in test_data.columns if any(word in col.lower() for word in ['price', 'close', 'open', 'high', 'low'])]
            print(f"[Debug] å¯èƒ½çš„åƒ¹æ ¼ç›¸é—œæ¬„ä½ï¼š{price_columns}")
    
    # 1. åŠ æ¬ŠæŒ‡æ•¸ (å˜—è©¦å¾å°è‚¡ç¸½è¦½ä¸­è¨ˆç®—æˆ–å°‹æ‰¾æŒ‡æ•¸è³‡æ–™)
    taiex_today = fetch_dataset('TaiwanStockInfo', today)
    taiex_prev = fetch_dataset('TaiwanStockInfo', prev)
    
    # å˜—è©¦ä¸åŒçš„æ¬„ä½åç¨±ä¾†å–å¾—æŒ‡æ•¸è³‡æ–™
    taiex_v = None
    taiex_prev_v = None
    
    if not taiex_today.empty:
        # å˜—è©¦å°‹æ‰¾æŒ‡æ•¸ç›¸é—œçš„è³‡æ–™
        index_stocks = taiex_today[taiex_today['stock_id'].isin(['0000', 'TAIEX', 'TWII'])]
        if not index_stocks.empty:
            print(f"[Debug] æ‰¾åˆ°æŒ‡æ•¸ç›¸é—œè‚¡ç¥¨ï¼š{index_stocks.to_dict()}")
            taiex_v = extract_single_value(index_stocks, 'close')
    
    if not taiex_prev.empty:
        index_stocks_prev = taiex_prev[taiex_prev['stock_id'].isin(['0000', 'TAIEX', 'TWII'])]
        if not index_stocks_prev.empty:
            taiex_prev_v = extract_single_value(index_stocks_prev, 'close')
    
    # 2. æ«ƒè²·æŒ‡æ•¸ (å˜—è©¦å¾å°è‚¡ç¸½è¦½ä¸­è¨ˆç®—æˆ–å°‹æ‰¾æŒ‡æ•¸è³‡æ–™)
    otc_today = fetch_dataset('TaiwanStockInfo', today)
    otc_prev = fetch_dataset('TaiwanStockInfo', prev)
    
    otc_v = None
    otc_prev_v = None
    
    if not otc_today.empty:
        # å˜—è©¦å°‹æ‰¾æ«ƒè²·æŒ‡æ•¸ç›¸é—œçš„è³‡æ–™
        otc_stocks = otc_today[otc_today['stock_id'].isin(['0001', 'TPEX', 'GTSM'])]
        if not otc_stocks.empty:
            print(f"[Debug] æ‰¾åˆ°æ«ƒè²·æŒ‡æ•¸ç›¸é—œè‚¡ç¥¨ï¼š{otc_stocks.to_dict()}")
            otc_v = extract_single_value(otc_stocks, 'close')
    
    if not otc_prev.empty:
        otc_stocks_prev = otc_prev[otc_prev['stock_id'].isin(['0001', 'TPEX', 'GTSM'])]
        if not otc_stocks_prev.empty:
            otc_prev_v = extract_single_value(otc_stocks_prev, 'close')
    
    # 3. èè³‡ç¶­æŒç‡ (ä½¿ç”¨å°è‚¡äº¤æ˜“æ—¥å ±)
    margin_today = fetch_dataset('TaiwanStockTradingDailyReport', today)
    margin_prev = fetch_dataset('TaiwanStockTradingDailyReport', prev)
    margin_v = extract_single_value(margin_today, 'margin_maintenance_ratio')
    margin_prev_v = extract_single_value(margin_prev, 'margin_maintenance_ratio')
    
    # 4. å€Ÿåˆ¸é¤˜é¡ (ä½¿ç”¨å°è‚¡äº¤æ˜“æ—¥å ±)
    short_today = fetch_dataset('TaiwanStockTradingDailyReport', today)
    short_prev = fetch_dataset('TaiwanStockTradingDailyReport', prev)
    short_v = extract_single_value(short_today, 'short_sale_balance')
    short_prev_v = extract_single_value(short_prev, 'short_sale_balance')
    
    # 5. å¤–è³‡æœŸè²¨å£æ•¸ (ä½¿ç”¨å°è‚¡äº¤æ˜“æ—¥å ±)
    futures_today = fetch_dataset('TaiwanStockTradingDailyReport', today)
    futures_prev = fetch_dataset('TaiwanStockTradingDailyReport', prev)
    futures_v = extract_single_value(futures_today, 'foreign_investor_net_position')
    futures_prev_v = extract_single_value(futures_prev, 'foreign_investor_net_position')
    
    # 6. å…«å¤§è¡Œåº«è²·è³£è¶… (ä½¿ç”¨å°è‚¡æ”¿åºœéŠ€è¡Œè²·è³£è¡¨)
    bank_today = fetch_dataset('TaiwanStockGovernmentBankBuySell', today)
    bank_prev = fetch_dataset('TaiwanStockGovernmentBankBuySell', prev)
    bank_v = extract_single_value(bank_today, 'net_buy_sell')
    bank_prev_v = extract_single_value(bank_prev, 'net_buy_sell')
    
    # 7. ä¸‰å¤§æ³•äººè²·è³£è¶… (ä½¿ç”¨å¯ç”¨çš„æ³•äººè²·è³£è¶…è³‡æ–™é›†)
    # é€™å€‹è³‡æ–™é›†éœ€è¦æ—¥æœŸç¯„åœæŸ¥è©¢ï¼Œæˆ‘å€‘ä½¿ç”¨å‰30å¤©ä½œç‚ºç¯„åœä¾†ç¢ºä¿æœ‰è³‡æ–™
    from datetime import datetime, timedelta
    
    # è¨ˆç®—å‰30å¤©çš„æ—¥æœŸä½œç‚º start_date
    today_dt = datetime.strptime(today, '%Y-%m-%d')
    prev_dt = datetime.strptime(prev, '%Y-%m-%d')
    
    start_date_today = (today_dt - timedelta(days=30)).strftime('%Y-%m-%d')
    start_date_prev = (prev_dt - timedelta(days=30)).strftime('%Y-%m-%d')
    
    print(f"[Debug] ä¸‰å¤§æ³•äººè²·è³£è¶…æŸ¥è©¢æ—¥æœŸç¯„åœï¼š{start_date_today} åˆ° {today}")
    inst_today = fetch_dataset('TaiwanStockInstitutionalInvestorsBuySell', today, prev_date=start_date_today)
    inst_prev = fetch_dataset('TaiwanStockInstitutionalInvestorsBuySell', prev, prev_date=start_date_prev)
    
    inst_v = None
    inst_prev_v = None
    
    if not inst_today.empty:
        print(f"[Debug] ä¸‰å¤§æ³•äººè²·è³£è¶…è³‡æ–™ï¼š{inst_today.to_dict()}")
        # å˜—è©¦è¨ˆç®—å¤–è³‡è²·è³£è¶…ï¼ˆForeign_Investor æ¬„ä½ï¼‰
        if 'Foreign_Investor' in inst_today.columns:
            inst_v = inst_today['Foreign_Investor'].iloc[0] if len(inst_today) > 0 else None
            print(f"[Debug] å¤–è³‡è²·è³£è¶…ï¼š{inst_v}")
    
    if not inst_prev.empty:
        if 'Foreign_Investor' in inst_prev.columns:
            inst_prev_v = inst_prev['Foreign_Investor'].iloc[0] if len(inst_prev) > 0 else None
    
    # 8. ä¸Šå¸‚ä¸Šæ¼²å®¶æ•¸ (å˜—è©¦å¾å°è‚¡ç¸½è¦½ä¸­è¨ˆç®—)
    adv_today = fetch_dataset('TaiwanStockInfo', today)
    adv_prev = fetch_dataset('TaiwanStockInfo', prev)
    
    adv_v = None
    adv_prev_v = None
    
    if not adv_today.empty:
        # å˜—è©¦è¨ˆç®—ä¸Šæ¼²å®¶æ•¸ï¼ˆå¦‚æœæœ‰åƒ¹æ ¼è³‡æ–™ï¼‰
        if 'close' in adv_today.columns and 'open' in adv_today.columns:
            # è¨ˆç®—ä¸Šæ¼²å®¶æ•¸ï¼ˆæ”¶ç›¤åƒ¹ > é–‹ç›¤åƒ¹ï¼‰
            adv_stocks = adv_today[adv_today['close'] > adv_today['open']]
            adv_v = len(adv_stocks)
            print(f"[Debug] è¨ˆç®—å¾—å‡ºä¸Šæ¼²å®¶æ•¸ï¼š{adv_v}")
        else:
            print(f"[Debug] ç„¡æ³•è¨ˆç®—ä¸Šæ¼²å®¶æ•¸ï¼Œç¼ºå°‘åƒ¹æ ¼è³‡æ–™")
    
    if not adv_prev.empty:
        if 'close' in adv_prev.columns and 'open' in adv_prev.columns:
            adv_stocks_prev = adv_prev[adv_prev['close'] > adv_prev['open']]
            adv_prev_v = len(adv_stocks_prev)
    
    # 9. ä¸Šå¸‚ä¸‹è·Œå®¶æ•¸ (å˜—è©¦å¾å°è‚¡ç¸½è¦½ä¸­è¨ˆç®—)
    dec_today = fetch_dataset('TaiwanStockInfo', today)
    dec_prev = fetch_dataset('TaiwanStockInfo', prev)
    
    dec_v = None
    dec_prev_v = None
    
    if not dec_today.empty:
        # å˜—è©¦è¨ˆç®—ä¸‹è·Œå®¶æ•¸ï¼ˆå¦‚æœæœ‰åƒ¹æ ¼è³‡æ–™ï¼‰
        if 'close' in dec_today.columns and 'open' in dec_today.columns:
            # è¨ˆç®—ä¸‹è·Œå®¶æ•¸ï¼ˆæ”¶ç›¤åƒ¹ < é–‹ç›¤åƒ¹ï¼‰
            dec_stocks = dec_today[dec_today['close'] < dec_today['open']]
            dec_v = len(dec_stocks)
            print(f"[Debug] è¨ˆç®—å¾—å‡ºä¸‹è·Œå®¶æ•¸ï¼š{dec_v}")
        else:
            print(f"[Debug] ç„¡æ³•è¨ˆç®—ä¸‹è·Œå®¶æ•¸ï¼Œç¼ºå°‘åƒ¹æ ¼è³‡æ–™")
    
    if not dec_prev.empty:
        if 'close' in dec_prev.columns and 'open' in dec_prev.columns:
            dec_stocks_prev = dec_prev[dec_prev['close'] < dec_prev['open']]
            dec_prev_v = len(dec_stocks_prev)
    
    # ç”Ÿæˆå ±è¡¨
    report = f"""å°è‚¡å¤§ç›¤æ—¥å ±ï¼š{today} (å°æ¯” {prev})
- åŠ æ¬ŠæŒ‡æ•¸ï¼š{fmt(taiex_v)} (vs {fmt(taiex_prev_v)})
- æ«ƒè²·æŒ‡æ•¸ï¼š{fmt(otc_v)} (vs {fmt(otc_prev_v)})
- èè³‡ç¶­æŒç‡(%)ï¼š{fmt(margin_v)} (vs {fmt(margin_prev_v)})
- å€Ÿåˆ¸é¤˜é¡ï¼š{fmt(short_v)} (vs {fmt(short_prev_v)})
- å¤–è³‡æœŸè²¨å£æ•¸ï¼š{fmt(futures_v)} (vs {fmt(futures_prev_v)})
- å…«å¤§è¡Œåº«è²·è³£è¶…ï¼š{fmt(bank_v)} (vs {fmt(bank_prev_v)})
- ä¸‰å¤§æ³•äººè²·è³£è¶…ï¼š{fmt(inst_v)} (vs {fmt(inst_prev_v)})
- ä¸Šå¸‚ä¸Šæ¼²å®¶æ•¸ï¼š{fmt(adv_v)} (vs {fmt(adv_prev_v)})
- ä¸Šå¸‚ä¸‹è·Œå®¶æ•¸ï¼š{fmt(dec_v)} (vs {fmt(dec_prev_v)})"""
    
    print(report)
    
    # ç™¼é€ LINE é€šçŸ¥
    send_line_push(report)


def main() -> None:
    # æš«æ™‚åœç”¨æ™‚é–“é™åˆ¶ä»¥ä¾¿æ¸¬è©¦
    # if not is_after_5pm_taipei():
    #     print("ç¾åœ¨æ™‚é–“æœªé” 17:00ï¼Œè«‹æ–¼ä¸‹åˆäº”é»å¾Œå†åŸ·è¡Œã€‚")
    #     sys.exit(0)

    run_analysis()


if __name__ == "__main__":
    main()
